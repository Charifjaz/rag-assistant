"""
Module d'indexation incr√©mentale pour un projet RAG.

Ce script :
- scanne tous les fichiers PDF dans le dossier `data/`
- ignore ceux d√©j√† index√©s (via un fichier `indexed_files.json`)
- construit ou met √† jour un vecteurstore FAISS
"""

import os
import glob
import json
from typing import List
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from app.utils import load_api_key
from app.config import DATA_FOLDER, VECTORSTORE_PATH, INDEX_TRACKING_FILE


def get_all_pdfs(folder_path: str) -> List[str]:
    """
    Liste tous les fichiers PDF dans un dossier.

    Args:
        folder_path (str): Chemin vers le dossier contenant les PDF.

    Returns:
        List[str]: Liste compl√®te des chemins vers les fichiers PDF.
    """
    return glob.glob(os.path.join(folder_path, "*.pdf"))


def load_indexed_files() -> List[str]:
    """
    Charge la liste des fichiers d√©j√† index√©s depuis un fichier JSON.

    Returns:
        List[str]: Liste des noms de fichiers d√©j√† index√©s.
    """
    if os.path.exists(INDEX_TRACKING_FILE):
        with open(INDEX_TRACKING_FILE, "r") as f:
            return json.load(f)
    return []


def save_indexed_files(file_list: List[str]):
    """
    Enregistre la liste des fichiers index√©s dans un fichier JSON.

    Args:
        file_list (List[str]): Liste mise √† jour des noms de fichiers index√©s.
    """
    os.makedirs(VECTORSTORE_PATH, exist_ok=True)  # Cree le dossier s'il n'existe pas
    with open(INDEX_TRACKING_FILE, "w") as f:
        json.dump(file_list, f, indent=2)


def load_documents(file_paths: List[str]) -> List:
    """
    Charge tous les documents PDF en objets LangChain.

    Args:
        file_paths (List[str]): Liste des chemins de fichiers √† charger.

    Returns:
        List[Document]: Liste de documents extraits.
    """
    all_docs = []
    for path in file_paths:
        loader = PyPDFLoader(path)
        docs = loader.load()
        # On ajoute le nom du fichier comme source dans les m√©tadonn√©es
        for doc in docs:
            doc.metadata["source"] = os.path.basename(path)
        all_docs.extend(docs)
    return all_docs


def build_incremental_vectorstore(
    data_folder: str, persist_path: str = VECTORSTORE_PATH
) -> None:
    """
    Construit ou met √† jour un vecteurstore FAISS de fa√ßon incr√©mentale.

    Seuls les fichiers PDF non encore index√©s seront trait√©s.

    Args:
        data_folder (str): Dossier contenant les fichiers PDF.
        persist_path (str): Chemin du vecteurstore √† cr√©er ou mettre √† jour.
    """
    load_api_key()  # Charge la cl√© OpenAI depuis le .env

    # Liste des fichiers actuels et de ceux d√©j√† index√©s
    all_files = get_all_pdfs(data_folder)
    already_indexed = load_indexed_files()

    # Filtrage : on ne garde que les nouveaux fichiers
    new_files = [f for f in all_files if os.path.basename(f) not in already_indexed]

    if not new_files:
        print("‚úÖ Aucun nouveau fichier √† indexer.")
        return

    print(f"üìÑ Nouveaux fichiers d√©tect√©s : {len(new_files)}")
    for f in new_files:
        print(" ‚Ä¢", f)

    # Chargement et d√©coupage des nouveaux documents
    documents = load_documents(new_files)
    splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    chunks = splitter.split_documents(documents)

    # Cr√©ation des embeddings √† partir des chunks
    embeddings = OpenAIEmbeddings()

    # Chargement ou cr√©ation du vecteurstore FAISS
    if os.path.exists(os.path.join(persist_path, "index.faiss")):
        vectordb = FAISS.load_local(
            persist_path, embeddings, allow_dangerous_deserialization=True
        )
        vectordb.add_documents(chunks)  # ajout des nouveaux chunks
    else:
        vectordb = FAISS.from_documents(chunks, embeddings)

    # Sauvegarde du vecteurstore mis √† jour
    vectordb.save_local(persist_path)

    # Mise √† jour de la liste des fichiers index√©s
    updated_indexed = list(
        set(already_indexed + [os.path.basename(f) for f in new_files])
    )
    save_indexed_files(updated_indexed)

    print(f"‚úÖ Index mis √† jour avec {len(new_files)} nouveau(x) fichier(s).")


if __name__ == "__main__":
    build_incremental_vectorstore(DATA_FOLDER)
