if __name__ == "__main__":
    import argparse
    from app import config
    from app.rag_engine import OpenAILLM, FAISSRetriever, RAGPipeline

    parser = argparse.ArgumentParser(
        description="Poser une question √† ton assistant RAG bas√© sur OpenAI"
    )

    parser.add_argument(
        "--model",
        type=str,
        default=config.DEFAULT_MODEL,
        help="Nom du mod√®le OpenAI (ex: gpt-3.5-turbo, gpt-4)",
    )
    parser.add_argument(
        "--temperature",
        type=float,
        default=config.DEFAULT_TEMPERATURE,
        help="Temp√©rature du mod√®le (0.0 = d√©terministe, 1.0 = cr√©atif)",
    )
    parser.add_argument(
        "--k",
        type=int,
        default=config.DEFAULT_K,
        help="Nombre de documents pertinents √† r√©cup√©rer",
    )
    parser.add_argument(
        "--question",
        type=str,
        required=False,
        help="Question √† poser (sinon pos√©e en interactif)",
    )

    args = parser.parse_args()

    # 1. R√©cup√©ration de la question
    question = args.question or input("‚ùì Pose ta question : ")

    # 2. Construction du pipeline
    retriever = FAISSRetriever(persist_path="vectorstore")
    llm = OpenAILLM(model_name=args.model, temperature=args.temperature)
    pipeline = RAGPipeline(retriever=retriever, llm=llm)

    # 3. Ex√©cution
    result = pipeline.ask(question, k=args.k)

    # 4. Affichage CLI
    print("üß† R√©ponse :\n", result["result"])
    print("\nüìÑ Sources :")
    for doc in result["source_documents"]:
        print("-", doc.metadata.get("source", "Sans source"))
